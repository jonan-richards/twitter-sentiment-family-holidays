{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install scikit-learn\n",
    "!pip install optunity\n",
    "!pip install pandas\n",
    "!pip install ipywidgets==7.* --user\n",
    "!pip install widgetsnbextension jupyter_contrib_nbextensions --user\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport classify_sentiment\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify_sentiment import SentimentClassification\n",
    "\n",
    "classification = SentimentClassification(\n",
    "    temp_dir='data/temp',\n",
    ")\n",
    "classification.load_lexicons({\n",
    "    'positive_path': 'data/lexicons/positive-words.txt',\n",
    "    'negative_path': 'data/lexicons/negative-words.txt',\n",
    "    'hashtag_path': 'data/lexicons/hashtag.txt',\n",
    "    'sent140_path': 'data/lexicons/sentiment140.txt',\n",
    "    'mpqa_path': 'data/lexicons/MPQA.csv',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'train'\n",
    "classification.load_train_data(text_path=f'data/tweeteval/{type}_text.txt', label_path=f'data/tweeteval/{type}_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.train_cross_validation(n_pos=350, n_word=450, n_char=450, log_C=-4.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.train_hyperparameter_optimalization(\n",
    "    n_svd_evals=30, n_classify_evals=5,\n",
    "    range_n_pos=[20, 21], \n",
    "    range_n_word=[50, 51], \n",
    "    range_n_char=[20, 21], \n",
    "    range_log_C=[-5, -4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.train(n_pos=350, n_word=450, n_char=450, log_C=-4.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.save_pipeline('models/classifier.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.load_pipeline('models/classifier.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.load_test_data(text_path='data/tweeteval/test_text.txt', label_path='data/tweeteval/test_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification.ablation(n_pos=350, n_word=450, n_char=450, log_C=-4.975))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'validation': {'positive': {'predicted': 1646.9, 'precision': 0.7250038537134043, 'recall': 0.6688891924482798, 'f1': 0.6957704921879808}, 'negative': {'predicted': 701.5, 'precision': 0.5202251788910066, 'recall': 0.5143125608375215, 'f1': 0.5171143221554984}, 'neutral': {'predicted': 2213.1, 'precision': 0.6686108253215285, 'recall': 0.7157164159271747, 'f1': 0.6913410274866695}, 'recall': 0.632972723070992, 'f1pn': 0.6064424071717396},\n",
    "    'test': {'positive': {'predicted': 2976, 'precision': 0.5218413978494624, 'recall': 0.6538947368421053, 'f1': 0.5804522519155298}, 'negative': {'predicted': 3039, 'precision': 0.6689700559394538, 'recall': 0.5118328298086606, 'f1': 0.5799457994579947}, 'neutral': {'predicted': 6269, 'precision': 0.6511405327803478, 'recall': 0.6875526360114536, 'f1': 0.6688513845649681}, 'recall': 0.6177600675540731, 'f1pn': 0.5801990256867623},\n",
    "    'ablation': {'counts': {'positive': {'predicted': 3215, 'precision': 0.4973561430793157, 'recall': 0.6732631578947369, 'f1': 0.5720930232558139}, 'negative': {'predicted': 3019, 'precision': 0.6618085458761179, 'recall': 0.5030211480362538, 'f1': 0.5715920469174653}, 'neutral': {'predicted': 6050, 'precision': 0.648099173553719, 'recall': 0.6604345629105609, 'f1': 0.6542087261199633}, 'recall': 0.6122396229471838, 'f1pn': 0.5718425350866396}, 'lexicon': {'positive': {'predicted': 3737, 'precision': 0.42253144233342255, 'recall': 0.6648421052631579, 'f1': 0.5166884816753926}, 'negative': {'predicted': 1893, 'precision': 0.6053882725832013, 'recall': 0.28851963746223563, 'f1': 0.3907928388746803}, 'neutral': {'predicted': 6654, 'precision': 0.5979861737300871, 'recall': 0.6702038066363484, 'f1': 0.6320387578429036}, 'recall': 0.541188516453914, 'f1pn': 0.45374066027503646}, 'lexicon_simple': {'positive': {'predicted': 3239, 'precision': 0.4871874035196048, 'recall': 0.6644210526315789, 'f1': 0.5621660135375847}, 'negative': {'predicted': 2679, 'precision': 0.6483762597984323, 'recall': 0.43731117824773413, 'f1': 0.5223274695534506}, 'neutral': {'predicted': 6366, 'precision': 0.6275526233113415, 'recall': 0.6728987704227725, 'f1': 0.6494350971307812}, 'recall': 0.5915436671006952, 'f1pn': 0.5422467415455177}, 'lexicon_hashtag': {'positive': {'predicted': 3479, 'precision': 0.47226214429433744, 'recall': 0.6917894736842105, 'f1': 0.5613255893406217}, 'negative': {'predicted': 2830, 'precision': 0.6710247349823322, 'recall': 0.4780966767371601, 'f1': 0.5583651867097912}, 'neutral': {'predicted': 5975, 'precision': 0.6435146443514644, 'recall': 0.6476334849250464, 'f1': 0.6455674949630624}, 'recall': 0.6058398784488057, 'f1pn': 0.5598453880252064}, 'lexicon_sent140': {'positive': {'predicted': 3279, 'precision': 0.4931381518755718, 'recall': 0.6808421052631579, 'f1': 0.5719844357976653}, 'negative': {'predicted': 2939, 'precision': 0.66485199047295, 'recall': 0.4919436052366566, 'f1': 0.5654753291853567}, 'neutral': {'predicted': 6066, 'precision': 0.6477085393999341, 'recall': 0.6617820448037729, 'f1': 0.6546696659168542}, 'recall': 0.6115225851011958, 'f1pn': 0.568729882491511}, 'lexicon_mpqa': {'positive': {'predicted': 3330, 'precision': 0.487987987987988, 'recall': 0.6842105263157895, 'f1': 0.5696757230499562}, 'negative': {'predicted': 3040, 'precision': 0.6575657894736842, 'recall': 0.5032729103726082, 'f1': 0.5701654306902452}, 'neutral': {'predicted': 5914, 'precision': 0.6462631044978018, 'recall': 0.6437594744820616, 'f1': 0.6450088600118133}, 'recall': 0.6104143037234865, 'f1pn': 0.5699205768701007}, 'ngrams': {'positive': {'predicted': 3526, 'precision': 0.38740782756664777, 'recall': 0.5751578947368421, 'f1': 0.46297237756312487}, 'negative': {'predicted': 2375, 'precision': 0.6610526315789473, 'recall': 0.39526686807653577, 'f1': 0.4947219158657635}, 'neutral': {'predicted': 6383, 'precision': 0.6011279962400126, 'recall': 0.6462860030318343, 'f1': 0.6228896103896103}, 'recall': 0.5389035886150707, 'f1pn': 0.47884714671444417}, 'ngram_pos': {'positive': {'predicted': 3361, 'precision': 0.48318952692650996, 'recall': 0.6837894736842105, 'f1': 0.5662482566248257}, 'negative': {'predicted': 2911, 'precision': 0.6660941257299897, 'recall': 0.4881671701913394, 'f1': 0.5634171146302485}, 'neutral': {'predicted': 6012, 'precision': 0.6448769128409847, 'recall': 0.6530234124978945, 'f1': 0.6489245962005189}, 'recall': 0.6083266854578149, 'f1pn': 0.5648326856275371}, 'ngram_word': {'positive': {'predicted': 3153, 'precision': 0.5033301617507137, 'recall': 0.6682105263157895, 'f1': 0.5741678726483358}, 'negative': {'predicted': 2952, 'precision': 0.6683604336043361, 'recall': 0.49672708962739176, 'f1': 0.5699017908723281}, 'neutral': {'predicted': 6179, 'precision': 0.6436316556077035, 'recall': 0.6698669361630453, 'f1': 0.6564872895344998}, 'recall': 0.6116015173687422, 'f1pn': 0.5720348317603319}, 'ngram_char': {'positive': {'predicted': 3432, 'precision': 0.4664918414918415, 'recall': 0.6741052631578948, 'f1': 0.5514034785603581}, 'negative': {'predicted': 2849, 'precision': 0.6658476658476659, 'recall': 0.47759315206445113, 'f1': 0.5562234276499047}, 'neutral': {'predicted': 6003, 'precision': 0.6428452440446444, 'recall': 0.6499915782381674, 'f1': 0.6463986599664991}, 'recall': 0.6005633311535045, 'f1pn': 0.5538134531051314}}\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation/test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "lines.append('\\\\begin{tabular}{r|cc}')\n",
    "lines.append('\\\\toprule')\n",
    "\n",
    "lines.append(' & '.join([\n",
    "    '',\n",
    "    'Validation',\n",
    "    'Test',\n",
    "]) + '\\\\\\\\')\n",
    "\n",
    "lines.append('\\\\midrule')\n",
    "\n",
    "lines.append('\\t' + ' & '.join([\n",
    "    'Avg. recall',\n",
    "    '{0:.2f}'.format(100 * results['validation']['recall']),\n",
    "    '{0:.2f}'.format(100 * results['test']['recall']),\n",
    "]) + '\\\\\\\\')\n",
    "\n",
    "lines.append('\\t' + ' & '.join([\n",
    "    '$F_1^{PN}$',\n",
    "    '{0:.2f}'.format(100 * results['validation']['f1pn']),\n",
    "    '{0:.2f}'.format(100 * results['test']['f1pn']),\n",
    "]) + '\\\\\\\\')\n",
    "\n",
    "for label_key, label in {label: label.capitalize() for label in ['positive', 'neutral', 'negative']}.items():\n",
    "    lines.append('\\\\midrule')\n",
    "\n",
    "    lines.append(f'\\\\multicolumn{{3}}{{c}}{{{label}}}\\\\\\\\')\n",
    "    lines.append('\\\\midrule')\n",
    "\n",
    "    for measure_key, measure in {'precision': 'Precision', 'recall': 'Recall', 'f1': '$F_1$'}.items():\n",
    "        lines.append('\\t' + ' & '.join([\n",
    "            measure,\n",
    "            '{0:.2f}'.format(100 * results['validation'][label_key][measure_key]),\n",
    "            '{0:.2f}'.format(100 * results['test'][label_key][measure_key]),\n",
    "        ]) + '\\\\\\\\')\n",
    "\n",
    "lines.append('\\\\bottomrule')\n",
    "lines.append('\\\\end{tabular}')\n",
    "\n",
    "table = '\\n'.join(lines)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "indent = '\\\\hspace{3mm}'\n",
    "\n",
    "lines.append('\\\\begin{tabular}{l|ll}')\n",
    "lines.append('\\\\toprule')\n",
    "\n",
    "lines.append(' & '.join([\n",
    "    'Excluded',\n",
    "    'Avg. recall',\n",
    "    '$F_1^{PN}$',\n",
    "]) + '\\\\\\\\')\n",
    "\n",
    "lines.append('\\\\midrule')\n",
    "\n",
    "lines.append('\\t' + ' & '.join([\n",
    "    'Baseline',\n",
    "    '{0:.2f}'.format(100 * results['test']['recall']),\n",
    "    '{0:.2f}'.format(100 * results['test']['f1pn']),\n",
    "]) + '\\\\\\\\')\n",
    "\n",
    "for exclude, exclude_label in {\n",
    "    'counts': 'Basic counts', \n",
    "    'lexicon': 'Lexicons', \n",
    "    'lexicon_simple': f'{indent}Hu', \n",
    "    'lexicon_sent140': f'{indent}Sentiment140',\n",
    "    'lexicon_hashtag': f'{indent}Hashtag',  \n",
    "    'lexicon_mpqa': f'{indent}MPQA',\n",
    "    'ngrams': 'N-grams', \n",
    "    'ngram_pos': f'{indent}POS-tag', \n",
    "    'ngram_word': f'{indent}Token', \n",
    "    'ngram_char': f'{indent}Character', \n",
    "}.items():\n",
    "    lines.append('\\t' + ' & '.join([\n",
    "        exclude_label,\n",
    "        '{0:.2f} ({1:.2f})'.format(100 * results['ablation'][exclude]['recall'], 100 * (results['ablation'][exclude]['recall'] - results['test']['recall'])),\n",
    "        '{0:.2f} ({1:.2f})'.format(100 * results['ablation'][exclude]['f1pn'], 100 * (results['ablation'][exclude]['f1pn'] - results['test']['f1pn'])),\n",
    "    ]) + '\\\\\\\\')\n",
    "\n",
    "lines.append('\\\\bottomrule')\n",
    "lines.append('\\\\end{tabular}')\n",
    "\n",
    "table = '\\n'.join(lines)\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('txmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3c288e7661af7b23b134bc6bbf12205a40e7750452aaaf289c8024ad83b85b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
